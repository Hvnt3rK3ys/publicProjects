# Documentación del Proyecto Final del curso Modelado y Simulación II

## Índice

1. **Introducción**
2. **Antecedentes**
   - 2.1. Pre-Transformers: Modelos Previos
   - 2.2. Desarrollo Matemático del Mecanismo de Atención
   - 2.3. Influencia del Paper "Attention is All You Need"
3. **Arquitectura Mamba**
4. **Análisis Topológico de Datos**
5. **Implementación con Transformers**
   - 5.1. Modelado de Series Temporales
   - 5.2. Dataset de Crímenes en Los Ángeles
6. **Resultados y Discusión**
7. **Conclusiones**
8. **Referencias**

---

## 1. Introducción

En esta sección, se proporciona una breve descripción del proyecto, incluyendo su objetivo principal y la relevancia del uso de técnicas de Deep Learning, específicamente Transformers, para modelar series temporales.

## 2. Antecedentes

### 2.1. Pre-Transformers: Modelos Previos

En esta sección, se discute la evolución de los modelos de Deep Learning antes de la introducción de los Transformers. Se mencionan modelos como RNN, LSTM, y su limitación en el manejo de secuencias largas.

### 2.2. Desarrollo Matemático del Mecanismo de Atención

Aquí se detalla el desarrollo matemático del mecanismo de atención, incluyendo las fórmulas y conceptos clave que permiten a los modelos enfocarse en partes específicas de la entrada.

### 2.3. Influencia del Paper "Attention is All You Need"

Se analiza el impacto del paper "Attention is All You Need" en el campo del Deep Learning, destacando cómo introdujo la arquitectura Transformer y revolucionó el procesamiento de secuencias.

## 3. Arquitectura Mamba

En esta sección, se describe la arquitectura Mamba, su relación con los Transformers, y cómo se integra en el proyecto. Se pueden incluir diagramas y explicaciones detalladas de su funcionamiento.

## 4. Análisis Topológico de Datos

Se presenta una introducción al análisis topológico de datos (TDA), su relevancia en el contexto del proyecto, y cómo se utiliza para comprender mejor las estructuras subyacentes en los datos.

## 5. Implementación con Transformers

### 5.1. Modelado de Series Temporales

Se explica cómo se utilizan los Transformers para modelar series temporales, incluyendo la preparación de los datos, la arquitectura del modelo, y las técnicas de entrenamiento.

### 5.2. Dataset de Crímenes en Los Ángeles

Se describe el dataset utilizado, incluyendo su origen, estructura, y cómo se preprocesa para ser utilizado en el modelo de Transformers.

## 6. Resultados y Discusión

En esta sección, se presentan los resultados obtenidos del modelo de Transformers aplicado al dataset de crímenes en Los Ángeles. Se discuten las métricas de rendimiento, las limitaciones encontradas, y posibles mejoras.

## 7. Conclusiones

Se resumen los hallazgos principales del proyecto, destacando la efectividad de los Transformers en el modelado de series temporales y las implicaciones de la arquitectura Mamba y el análisis topológico de datos.

## 8. Referencias

Se listan todas las referencias utilizadas en el proyecto, incluyendo papers, libros, y otros recursos que aportaron al desarrollo del proyecto.

